{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torchvision\r\n",
    "import torchvision.datasets as datasets\r\n",
    "import torchvision.transforms as transforms\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "class Discriminator (nn.Module):\r\n",
    "    def __init__(self, img_dim):\r\n",
    "        super().__init__()\r\n",
    "        self.disc = nn.Sequential(\r\n",
    "            nn.Linear(img_dim, 128),\r\n",
    "            nn.LeakyReLU(0.1),\r\n",
    "            nn.Linear(128, 1),\r\n",
    "            nn.Sigmoid()\r\n",
    "        )\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        return self.disc(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "class Generator(nn.Module):\r\n",
    "    def __init__(self, z_dim, img_dim):\r\n",
    "        super().__init__()\r\n",
    "        self.gen = nn.Sequential(\r\n",
    "            nn.Linear(z_dim, 256),\r\n",
    "            nn.LeakyReLU(0.1),\r\n",
    "            nn.Linear(256, img_dim),\r\n",
    "            nn.Tanh()\r\n",
    "        )\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        return self.gen(x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n",
    "lr = 3e-4\r\n",
    "z_dim = 64\r\n",
    "img_dim = 28*28*1\r\n",
    "batch_size = 32\r\n",
    "num_epochs = 50"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "\r\n",
    "disc = Discriminator(img_dim).to(device)\r\n",
    "gen = Generator(z_dim, img_dim).to(device)\r\n",
    "fixed_noise = torch.randn(batch_size, z_dim).to(device)\r\n",
    "transform = transforms.Compose([\r\n",
    "  transforms.ToTensor(),\r\n",
    "  transforms.Normalize(\r\n",
    "    (0.5,),\r\n",
    "    (0.5,)\r\n",
    "  )\r\n",
    "])\r\n",
    "dataset = datasets.MNIST(\r\n",
    "  root=\"./dataset/\", \r\n",
    "  transform=transform,\r\n",
    "  download=True\r\n",
    ")\r\n",
    "loader= DataLoader(dataset, batch_size, shuffle=True)\r\n",
    "\r\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\r\n",
    "opt_gen= optim.Adam(gen.parameters(), lr=lr)\r\n",
    "\r\n",
    "criterion = nn.BCELoss()\r\n",
    "writer_fake = SummaryWriter(f\"./runs/GAN_MNIST/fake\")\r\n",
    "writer_real = SummaryWriter(f\"./runs/GAN_MNIST/real\")\r\n",
    "step = 0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "for epoch in range(num_epochs):\r\n",
    "  for batch_idx, (real, _) in enumerate(loader):\r\n",
    "    real = real.view(-1, 784).to(device)\r\n",
    "    batch_size = real.shape[0]\r\n",
    "\r\n",
    "    noise = torch.randn(batch_size, z_dim).to(device)\r\n",
    "    fake = gen(noise)\r\n",
    "\r\n",
    "    disc_real = disc(real).view(-1)\r\n",
    "    lossD_real = criterion(disc_real, torch.ones_like(disc_real))\r\n",
    "\r\n",
    "    # don't want opt_disc.step() update fake, so create a detached version fake at this point\r\n",
    "    # also the gradient that is used to update disc has nothing to do with gen\r\n",
    "    # as the graph of fake involve gen, we have to detach fake to avoid affecting gen itself\r\n",
    "    \r\n",
    "    disc_fake = disc(fake.detach()).view(-1)\r\n",
    "    lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\r\n",
    "\r\n",
    "    lossD = (lossD_real + lossD_fake)/2\r\n",
    "    \r\n",
    "    disc.zero_grad()\r\n",
    "    lossD.backward()\r\n",
    "    opt_disc.step()\r\n",
    "\r\n",
    "    output = disc(fake).view(-1)\r\n",
    "    lossG = criterion(output, torch.ones_like(output))\r\n",
    "    gen.zero_grad()\r\n",
    "    lossG.backward()\r\n",
    "    opt_gen.step()\r\n",
    "\r\n",
    "    if batch_idx == 0:\r\n",
    "        print(\r\n",
    "            f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\r\n",
    "                    Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\r\n",
    "        )\r\n",
    "\r\n",
    "        with torch.no_grad():\r\n",
    "            fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\r\n",
    "            data = real.reshape(-1, 1, 28, 28)\r\n",
    "            img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\r\n",
    "            img_grid_real = torchvision.utils.make_grid(data, normalize=True)\r\n",
    "\r\n",
    "            writer_fake.add_image(\r\n",
    "                \"Mnist Fake Images\", img_grid_fake, global_step=step\r\n",
    "            )\r\n",
    "            writer_real.add_image(\r\n",
    "                \"Mnist Real Images\", img_grid_real, global_step=step\r\n",
    "            )\r\n",
    "            step += 1\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch [0/50] Batch 0/1875                     Loss D: 0.6798, loss G: 0.6657\n",
      "Epoch [1/50] Batch 0/1875                     Loss D: 0.6073, loss G: 0.8925\n",
      "Epoch [2/50] Batch 0/1875                     Loss D: 0.3536, loss G: 1.3072\n",
      "Epoch [3/50] Batch 0/1875                     Loss D: 0.3749, loss G: 1.4472\n",
      "Epoch [4/50] Batch 0/1875                     Loss D: 0.6495, loss G: 0.9522\n",
      "Epoch [5/50] Batch 0/1875                     Loss D: 0.5699, loss G: 1.0106\n",
      "Epoch [6/50] Batch 0/1875                     Loss D: 0.6386, loss G: 1.1112\n",
      "Epoch [7/50] Batch 0/1875                     Loss D: 0.5836, loss G: 0.9521\n",
      "Epoch [8/50] Batch 0/1875                     Loss D: 0.3807, loss G: 1.5441\n",
      "Epoch [9/50] Batch 0/1875                     Loss D: 0.5309, loss G: 0.9624\n",
      "Epoch [10/50] Batch 0/1875                     Loss D: 0.5184, loss G: 1.0213\n",
      "Epoch [11/50] Batch 0/1875                     Loss D: 0.4975, loss G: 1.1149\n",
      "Epoch [12/50] Batch 0/1875                     Loss D: 0.8079, loss G: 0.8613\n",
      "Epoch [13/50] Batch 0/1875                     Loss D: 0.5887, loss G: 1.3113\n",
      "Epoch [14/50] Batch 0/1875                     Loss D: 0.7186, loss G: 0.9049\n",
      "Epoch [15/50] Batch 0/1875                     Loss D: 0.8144, loss G: 0.9303\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('dl': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "6b1f039069d6172ef73d0b939796bfc9640c29d76fb9386aa8f90c7cbce2c865"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}